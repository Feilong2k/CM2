# Tool Result Cache: How It Works with Orion

## The Big Picture

Orion (the LLM) is **stateless** – it doesn't remember anything between turns. The system (ToolOrchestrator and friends) provides Orion with the last 20 messages (conversation history) as context for each turn. When Orion uses a tool (e.g., reads a file), the system executes the tool and returns the result, which is then added to the conversation history.

The **ToolResultCacheService** is a performance optimization that sits **between** the ToolOrchestrator and the actual tool execution. It stores tool results so that if the same tool call is made again (with the same arguments, within the cache validity period), the system can return the cached result **without re‑executing the tool**.

## Step‑by‑Step Example

Imagine Orion needs to read a file `example.txt`:

### Without Cache
1. Orion sends a tool call: `FileSystemTool_read({path: "example.txt"})`
2. System runs the `read` method of `FileSystemTool`, which reads the file from disk.
3. System returns the file content to Orion.
4. The tool call and result are added to the conversation history.

### With Cache
1. Orion sends the same tool call: `FileSystemTool_read({path: "example.txt"})`
2. The ToolOrchestrator checks if a `ToolResultCacheService` instance is available and if the tool is cacheable (FileSystemTool, DatabaseTool, search_files).
3. If cacheable, the cache service generates a **cache key** from:
   - Project ID
   - Tool name (`FileSystemTool`)
   - Action (`read`)
   - Hash of the arguments (`{path: "example.txt"}`)
4. The cache service looks up the key in its store.
   - **Cache hit** (valid entry found):
     - Returns the cached file content immediately.
     - No disk I/O occurs.
   - **Cache miss** (no valid entry):
     - Executes the tool (reads the file from disk).
     - Stores the result in the cache (with a timestamp and a **fingerprint**).
     - Returns the result.
5. The ToolOrchestrator receives the result (identical to the non‑cached version) and passes it to Orion.
6. The tool call and result are added to the conversation history – **Orion sees exactly the same data as without cache**.

## Key Points

### Transparency
- **Orion never knows whether a result came from the cache or fresh execution.** The interface is identical.
- The cache is an **implementation detail** of the system, not part of Orion’s “knowledge.”

### Freshness Guarantees
The cache is not a permanent store; it respects changes in the underlying data:
- **TTL (Time‑To‑Live)**: Each entry expires after a configurable time (default 10 minutes).
- **Fingerprint invalidation**:
  - For files: the current git commit hash (if the file changes in git, the cache is invalidated).
  - For database: the schema version (if the DB schema changes, cached queries are invalidated).
  - For other tools: a default fingerprint.

### What Gets Cached
Only **idempotent, read‑heavy** tools:
- `FileSystemTool_read`, `FileSystemTool_list_files`, `FileSystemTool_search_files`
- `DatabaseTool_query`
- `search_files` (the standalone tool)

Write operations (`FileSystemTool_write`, `DatabaseTool_execute`) are **not cached** because they change state.

### System Context vs. Cache
- **System context** = the 20 most recent messages (conversation history) sent to the LLM. This includes tool calls and their results (whether cached or not).
- **Cache** = a fast‑lookup store for tool results. It does not alter the system context; it only changes how the result is obtained.

## Why Use a Cache?

1. **Speed**: Reading a file from disk (or querying a database) is slower than reading from memory. Cache hits are typically 10–100× faster.
2. **Reduced load**: Avoids repeated I/O operations for the same data.
3. **Cost**: If using paid LLM APIs, faster tool execution means shorter overall turns, which can reduce token usage.

## Example Timeline

```
Time 0: Orion asks to read "example.txt"
        → Cache miss → read from disk → store in cache → return content

Time +1 sec: Orion asks again (same arguments)
        → Cache hit → return cached content (no disk read)

Time +10 min (TTL expired): Orion asks again
        → Cache expired → read from disk → store fresh content → return
```

## Observability

Cache events are emitted as **trace events**:
- `cache_hit`, `cache_miss`, `cache_expired`, `cache_invalidated`

You can see these in:
- The console (if `verbose` mode is on)
- The trace store (database)
- The log file generated by the demo script (`backend/scripts/cache_demo.log`)

## Troubleshooting: Signs the Cache May Not Be Working

If the tool result cache is not functioning as expected, look for these indicators:

### 1. **Log/Trace Indicators (Direct Evidence)**
- **No cache‑related trace events** (`cache_hit`, `cache_miss`, etc.) appear in console, trace store, or log files.
- **Only `cache_miss` events, never `cache_hit`** – suggests the cache is never returning cached entries.
- **Unexpected `cache_invalidated` events** – fingerprint changes too frequently (e.g., git hash changing on every call).

### 2. **Performance Indicators**
- **Tool execution times remain consistently slow** even for repeated identical calls.
- **No speed‑up** on second identical request (cache hit should be 10–100× faster).
- **High disk I/O or database queries** for repeated reads that should be cached.

### 3. **Behavioral Symptoms**
- **Orion receives stale data** – e.g., file content after it has been changed, but Orion still sees old content (TTL/fingerprint invalidation failing).
- **Orion sees duplicate results** – cache not deduplicating identical calls within the same turn.
- **Memory growth** – cache entries never evicted (LRU or TTL not working).

### 4. **Validation Steps**
1. **Run the demo script** and check the log:
   ```bash
   node backend/scripts/test_cache_demo.js
   ```
   Expected pattern: first call → `cache_miss`, second identical call → `cache_hit`.

2. **Enable verbose traces** in CLI:
   ```bash
   node bin/orion-cli.js --project-id test --verbose
   ```
   Look for `[TRACE]` lines containing `cache_` events.

3. **Check cache configuration** – ensure `ToolOrchestrator` is instantiated with a `toolResultCache` parameter.

4. **Monitor cache stats** via the service’s `stats()` method (size, maxSize, ttlSeconds).

5. **Force a cache‑invalidation scenario**:
   - Change a file that Orion has read (should trigger `cache_invalidated` on next read if git hash changes).
   - Wait longer than the TTL (default 10 minutes) and repeat a call (should see `cache_expired`).

### 5. **Common Pitfalls**
- **Cache not enabled** – `ToolOrchestrator` created without passing `toolResultCache` option.
- **Non‑cacheable tools** – only `FileSystemTool_*`, `DatabaseTool_*`, and `search_files` are cached; writes are not.
- **Different arguments** – slight variation (e.g., extra space) produces a different cache key.
- **Project‑ID mismatch** – cache keys include `projectId`; different projects won’t share cache.
- **Fingerprint failures** – git not available in environment, or DB schema version not accessible.

### Quick Diagnostic Command
```bash
cd backend && npx jest src/services/__tests__/ToolResultCacheService.integration.spec.js --verbose
```
If all tests pass, the cache service itself is functional; integration may be the issue.

## Summary

The cache is a **transparent performance optimization** that does not change Orion’s behavior or the data it receives. It simply avoids redundant work when the same tool call is repeated within a short time frame, while ensuring freshness through TTL and fingerprint invalidation.

Orion remains stateless; the cache is a system‑level mechanism that speeds up tool execution without altering the LLM’s experience.
